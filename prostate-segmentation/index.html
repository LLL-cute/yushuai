<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link href="main.css" rel="stylesheet" media="all">
<meta name="description" content="Automated Melanoma Recognition via Very Deep Residual Networks" />
<meta name="keywords" content="Automated melanoma recognition, very deep convolutional neural networks, residual learning, fully convolutional neural networks, skin lesion analysis">
<script>
function buttonSwitch(id, text)
{
	old_src = document.getElementById(id).src;
	ind = old_src.lastIndexOf('/');
	document.getElementById(id).src = old_src.substr(0,ind+1) + text;
}


</script>
<title>Volumetric ConvNets with Mixed Residual Connections for Automated Prostate Segmentation from 3D MR Images </title>
</head>

<body>

<div id="top_arrow" style="position: fixed; bottom: 10px; right: 10px;">
<a href="#title">
<img src="./figures/top_arrow.jpg" style="border: 0pt none ; width: 26px; height: 32px;"/></a>
</div>


<h2 id="title" class="auto-style1">
<!--<img alt="" class="style4" height="135" src="figures/siga_2012.jpg" style="float: left" width="123">-->
Volumetric ConvNets with Mixed Residual Connections for Automated Prostate Segmentation from 3D MR Images</h2>
<p class="auto-style7"  align="center">
	<a href="http://appsrv.cse.cuhk.edu.hk/~lqyu/" target="_blank">Lequan Yu</a><sup>1</sup> &nbsp;&nbsp;&nbsp;
    <a href="http://appsrv.cse.cuhk.edu.hk/~xinyang/" target="_blank">Xin Yang</a><sup>1</sup>&nbsp;&nbsp;&nbsp;
	<a href="http://appsrv.cse.cuhk.edu.hk/~hchen/" target="_blank">Hao Chen</a><sup>1</sup> &nbsp;&nbsp;&nbsp;
	<a href="http://sn.polyu.edu.hk/en/people/academic_staff/#harry.qin" target="_blank">Jing Qin</a><sup>2</sup>&nbsp;&nbsp;&nbsp;
	<a href="http://www.cse.cuhk.edu.hk/~pheng/" target="_blank">Pheng Ann Heng</a><sup>1</sup>&nbsp;&nbsp;&nbsp;
</p>

<p class="auto-style7"  align="center"><sup>1</sup>The Chinese Univeristy of Hong Kong&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>2</sup>The Hong Kong Polytechnic University</p>
<!--<p class="auto-style7"  align="center">&nbsp;&nbsp;&nbsp; </p>-->
<p align=left>&nbsp;</p>
<p align="center">
<table style="width:960px" align="center">
<tr>
	<td><img width=690px alt="" src="figures/teaser1.png"></td>	
</tr>
<tr>
	<td><p class="auto-style5">Example of prostate MR images displaying large variations (only show the center slice of prostates in 3D MR
images and the yellow contours indicate prostates).</p></td>
</tr>
</table>

<p class="style2"><strong><span class="auto-style4">Abstract</span></strong></p>
<p align="justify",class="auto-style5"> Automated prostate segmentation from 3D MR images is very challenging due to large variations of prostate shape and indistinct prostate boundaries. We propose a novel volumetric convolutional neural network (ConvNet) with mixed residual connections to cope with this challenging problem. Compared with previous methods, our volumetric ConvNet has two compelling advantages. First, it is implemented in a 3D manner and can fully exploit the 3D spatial contextual information of input data to perform efficient, precise and volume-to-volume prediction. Second and more important, the novel combination of residual connections (i.e., long and short) can
greatly improve the training efficiency and discriminative capability of our network by enhancing the information propagation within the ConvNet both locally and globally. While the forward propagation of location information can improve the segmentation accuracy, the smooth backward propagation of gradient flow can accelerate the convergence speed and enhance the discrimination capability. Extensive experiments
on the open <a href="https://promise12.grand-challenge.org/results/">MICCAI PROMISE12 challenge</a> dataset corroborated the effectiveness of the proposed volumetric ConvNet with mixed residual connections. Our method ranked the first in the challenge, outperforming other competitors by a large margin with respect to most of evaluation metrics. The proposed volumetric ConvNet is general enough and can be easily extended to other medical image analysis tasks, especially ones with limited training data.</p>

<p class="auto-style5">&nbsp;</p>



<p id="Method", class="auto-style4"><strong>Method</strong></p>
<table width="100%" align="center">
<tr>
	<td><img width="900px" alt="" src="figures/method1.png"></td>	
</tr>
<tr>
	<td><p class="auto-style5">(a) The architecture of the proposed volumetric ConvNet. The number in each box represents the number of feature
maps and all convolutional layers contain 3×3×3 filter kernels. (b) The illustration of one residual block.</p></td>
</tr>
</table>
<p class="auto-style5">&nbsp;</p>


<p id="Results", class="auto-style4"><strong>Results</strong></p>
<table width="100%">
<tr>
    <td width="5%"></td>
    <td width="90%">
        <div><img src="figures/result11.png" width="700px">
        <p align="justify" class="auto-style5">Qualitative segmentation results of case 4 (first row) and case 22 (second row) at the apex(left), center (middle) and base (right) of the prostate in testing dataset. The yellow and red contours indicate the ground truth and our segmentation results. More results can be found in <a href="https://grand-challenge.org/site/promise12/resultpro/?id=CUMED&folder=20160606000157_2700_CUMED_Results">challenge website</a>.</p>
        </div>
    </td>
    <td width="5%"></td>
</tr>
</table>
<p></p>
<table>
<tr>
    <td width="5%"></td>
    <td width="90%">
        <div><img src="figures/result21.png" width="900px">
        <p align="justify" class="auto-style5">Quantitative comparison between the proposed method and other methods. Complete results can be found in <a href="https://promise12.grand-challenge.org/results/">challenge website</a>.</p>
        </div>
    </td>
    <td width="5%"></td>
</tr>
</table>
<p class="auto-style5">&nbsp;</p>



<p id="downloads", class="auto-style4"><strong>Downloads</strong></p>

<table cellSpacing=4 cellPadding=2 border=0 style="width: 90%">
<tr COLSPAN="2">
	<td align="center" valign="center">
		<img style="padding:0; clear:both; " src="figures/paper_icon1.png" align="middle" alt="Snapshot for paper" class="pdf" width="210" />
	</td>
	<td align="left" class="auto-style5">"Volumetric ConvNets with Mixed Residual Connections for Automated Prostate Segmentation from 3D MR Images&quot;, AAAI 2017<br>Lequan Yu, Xin Yang, Hao Chen, Jing Qin, Pheng Ann Heng.<br><br>
<img alt="" height="32" src="figures/pdf_icon.gif" width="31">&nbsp;&nbsp;[<a href="http://appsrv.cse.cuhk.edu.hk/~lqyu/papers/AAAI17_Prostate.pdf">Paper</a>]<br><br> 
<img alt="" height="32" width="32" src="figures/github_icons.jpg">&nbsp;[<a href="https://github.com/yulequan/Volumetric-ConvNet-for-prostate-segmentation">Code</a>] <!--Please download from <a href="https://www.dropbox.com/s/925xcxlvohd0hco/%5BEG_code_data%5D_release.zip?dl=0">Dropbox</a> or <a href="http://pan.baidu.com/s/1bQ4yHC">Baiduyun</a>.--> <br><br> &nbsp;
</td>
</tr>
</table>
<br>

<p class="auto-style1"><font color="#999999">Last update: Feb., 2017</font></p>


</body>

</html>
